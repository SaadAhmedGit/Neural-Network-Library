# Neural-Network-Library-From-Scratch

Note: This is not intended for professional use for obvious reasons and is just a fun personal project. <br/>
Also, do have a look at *mnist-example.ipynb* to see how to use it. Although, it's pretty intuitive and is quite similar to the beginner-friendly Keras's API
## Supported Activation functions
* Sigmoid
* ReLu
* Tanh
### Under progress
* Softmax
## Supported Loss functions
* Mean Squared Error
### Under progress
* Binary Cross Entropy
